{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Trading Signals with LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create trading signals and adjust parameters for the ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:53.361121Z",
     "start_time": "2020-06-21T03:15:53.359422Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.473652Z",
     "start_time": "2020-06-21T03:15:53.619170Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.477216Z",
     "start_time": "2020-06-21T03:15:54.474618Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import MultipleTimeSeriesCV, format_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.489618Z",
     "start_time": "2020-06-21T03:15:54.478409Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:54.626839Z",
     "start_time": "2020-06-21T03:15:54.624975Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "YEAR = 252\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '2012-01-01'\n",
    "END = '2019-12-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the train and validation sets, and identify labels and features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.610627Z",
     "start_time": "2020-06-21T03:15:56.699840Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1896265 entries, ('AAON', Timestamp('2012-01-02 00:00:00')) to ('ZWS', Timestamp('2019-12-31 00:00:00'))\n",
      "Data columns (total 35 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   dollar_vol       1896265 non-null  float64\n",
      " 1   dollar_vol_rank  1896265 non-null  float64\n",
      " 2   rsi              1893783 non-null  float64\n",
      " 3   bb_high          1892898 non-null  float64\n",
      " 4   bb_low           1892891 non-null  float64\n",
      " 5   SAR              1896084 non-null  float64\n",
      " 6   NATR             1893783 non-null  float64\n",
      " 7   ATR              1893783 non-null  float64\n",
      " 8   PPO              1891836 non-null  float64\n",
      " 9   MACD             1890420 non-null  float64\n",
      " 10  sector           1896265 non-null  int32  \n",
      " 11  r01              1896084 non-null  float64\n",
      " 12  r05              1895376 non-null  float64\n",
      " 13  r10              1894491 non-null  float64\n",
      " 14  r21              1892544 non-null  float64\n",
      " 15  r42              1888826 non-null  float64\n",
      " 16  r63              1885088 non-null  float64\n",
      " 17  r01dec           1828218 non-null  float64\n",
      " 18  r05dec           1895376 non-null  float64\n",
      " 19  r10dec           1894491 non-null  float64\n",
      " 20  r21dec           1892544 non-null  float64\n",
      " 21  r42dec           1888826 non-null  float64\n",
      " 22  r63dec           1885088 non-null  float64\n",
      " 23  r01q_sector      1828218 non-null  float64\n",
      " 24  r05q_sector      1895376 non-null  float64\n",
      " 25  r10q_sector      1894491 non-null  float64\n",
      " 26  r21q_sector      1892544 non-null  float64\n",
      " 27  r42q_sector      1888826 non-null  float64\n",
      " 28  r63q_sector      1885088 non-null  float64\n",
      " 29  r01_fwd          1896261 non-null  float64\n",
      " 30  r05_fwd          1896261 non-null  float64\n",
      " 31  r21_fwd          1896261 non-null  float64\n",
      " 32  year             1896265 non-null  int64  \n",
      " 33  month            1896265 non-null  int64  \n",
      " 34  weekday          1896265 non-null  int64  \n",
      "dtypes: float64(31), int32(1), int64(3)\n",
      "memory usage: 506.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data = (pd.read_hdf('data.h5', 'model_data')\n",
    "            .sort_index()\n",
    "            .loc[idx[:, START:END], :]) # train & validation period\n",
    "data.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.627071Z",
     "start_time": "2020-06-21T03:15:58.611792Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='_fwd').columns)\n",
    "features = data.columns.difference(labels).tolist() # features are columns not containing '_fwd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: Lookback, lookahead and roll-forward periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.713463Z",
     "start_time": "2020-06-21T03:15:58.628189Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tickers = data.index.get_level_values('symbol').unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to predict 1, 5 or 21-day returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.716838Z",
     "start_time": "2020-06-21T03:15:58.714860Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.726739Z",
     "start_time": "2020-06-21T03:15:58.718248Z"
    }
   },
   "outputs": [],
   "source": [
    "categoricals = ['year', 'month', 'sector', 'weekday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select 4.5 and one years as the length of our training periods; test periods are one and three months long. Since we are using two years (2015/16) for validation, a one-month test period implies 24 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.735386Z",
     "start_time": "2020-06-21T03:15:58.728023Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 253), 253]\n",
    "test_lengths = [253, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.743174Z",
     "start_time": "2020-06-21T03:15:58.737182Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_params = list(product(lookaheads, train_lengths, test_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:15:58.751241Z",
     "start_time": "2020-06-21T03:15:58.744605Z"
    }
   },
   "outputs": [],
   "source": [
    "results_path = Path('results', 'us_stocks')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We always want to know how much our (gradient boosting) is improving over a simpler baseline (if at all..)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:16:05.129548Z",
     "start_time": "2020-06-21T03:16:05.127693Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.679350Z",
     "start_time": "2020-06-21T03:16:05.270137Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [03:24<00:00, 17.07s/it]\n"
     ]
    }
   ],
   "source": [
    "lr_metrics = []\n",
    "\n",
    "# iterate over our three CV configuration parameters\n",
    "for lookahead, train_length, test_length in tqdm(test_params):\n",
    "    label = f'r{lookahead:02}_fwd'\n",
    "    df = pd.get_dummies(data.loc[:, features + [label]].dropna(), \n",
    "                        columns=categoricals, \n",
    "                        drop_first=True)\n",
    "    X, y = df.drop(label, axis=1), df[label]\n",
    "\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              test_period_length=test_length,\n",
    "                              lookahead=lookahead,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    ic, preds = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(cv.split(X=X)):\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        preds.append(y_test.to_frame('y_true').assign(y_pred=y_pred))\n",
    "        ic.append(spearmanr(y_test, y_pred)[0])\n",
    "    preds = pd.concat(preds)\n",
    "    lr_metrics.append([lookahead, \n",
    "                       train_length, \n",
    "                       test_length,\n",
    "                       np.mean(ic),\n",
    "                       spearmanr(preds.y_true, preds.y_pred)[0]\n",
    "                      ])\n",
    "\n",
    "columns = ['lookahead', 'train_length', 'test_length', 'ic_by_day', 'ic']\n",
    "lr_metrics = pd.DataFrame(lr_metrics, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information Coefficient - Distribution by Lookahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.897475Z",
     "start_time": "2020-06-21T03:19:37.680445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(14,5), sharey=True)\n",
    "\n",
    "# plot average of daily IC values\n",
    "sns.boxplot(x='lookahead', y='ic_by_day',data=lr_metrics, ax=axes[0])\n",
    "axes[0].set_title('IC by Day')\n",
    "\n",
    "# plot IC across all predictions\n",
    "sns.boxplot(x='lookahead', y='ic',data=lr_metrics, ax=axes[1])\n",
    "axes[1].set_title('IC Overall')\n",
    "axes[0].set_ylabel('Information Coefficient')\n",
    "axes[1].set_ylabel('')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one- and five-day return forecasts, shorter train- and test-length yield better results in terms of daily avg IC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.911949Z",
     "start_time": "2020-06-21T03:19:37.898655Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lookahead</th>\n",
       "      <th>train_length</th>\n",
       "      <th>test_length</th>\n",
       "      <th>ic_by_day</th>\n",
       "      <th>ic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>21</td>\n",
       "      <td>0.061836</td>\n",
       "      <td>0.025962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1138</td>\n",
       "      <td>21</td>\n",
       "      <td>0.029028</td>\n",
       "      <td>-0.017967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1138</td>\n",
       "      <td>253</td>\n",
       "      <td>-0.008058</td>\n",
       "      <td>-0.008058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>253</td>\n",
       "      <td>21</td>\n",
       "      <td>0.123319</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1138</td>\n",
       "      <td>21</td>\n",
       "      <td>0.083903</td>\n",
       "      <td>-0.031678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1138</td>\n",
       "      <td>253</td>\n",
       "      <td>-0.046700</td>\n",
       "      <td>-0.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>253</td>\n",
       "      <td>21</td>\n",
       "      <td>0.121101</td>\n",
       "      <td>0.025275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>1138</td>\n",
       "      <td>21</td>\n",
       "      <td>0.111931</td>\n",
       "      <td>-0.016153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>1138</td>\n",
       "      <td>253</td>\n",
       "      <td>0.052140</td>\n",
       "      <td>0.052140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lookahead  train_length  test_length  ic_by_day        ic\n",
       "3           1           253           21   0.061836  0.025962\n",
       "1           1          1138           21   0.029028 -0.017967\n",
       "0           1          1138          253  -0.008058 -0.008058\n",
       "7           5           253           21   0.123319  0.050678\n",
       "5           5          1138           21   0.083903 -0.031678\n",
       "4           5          1138          253  -0.046700 -0.046700\n",
       "11         21           253           21   0.121101  0.025275\n",
       "9          21          1138           21   0.111931 -0.016153\n",
       "8          21          1138          253   0.052140  0.052140"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(lr_metrics.groupby('lookahead', group_keys=False)\n",
    " .apply(lambda x: x.nlargest(3, 'ic_by_day')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.920850Z",
     "start_time": "2020-06-21T03:19:37.913179Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_metrics.to_csv(results_path / 'lin_reg_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook example iterates over many configurations, optionally using random samples to speed up model selection using a diverse subset. The goal is to identify the most impactful parameters without trying every possible combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.935808Z",
     "start_time": "2020-06-21T03:19:37.921761Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_fi(model):\n",
    "    \"\"\"Return normalized feature importance as pd.Series\"\"\"\n",
    "    fi = model.feature_importance(importance_type='gain')\n",
    "    return (pd.Series(fi / fi.sum(),\n",
    "                      index=model.feature_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `base_params` are not affected by cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.943601Z",
     "start_time": "2020-06-21T03:19:37.936926Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_params = dict(boosting='gbdt',\n",
    "                   objective='regression',\n",
    "                   verbose=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following parameters and values to select our best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.952308Z",
     "start_time": "2020-06-21T03:19:37.944671Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# constraints on structure (depth) of each tree\n",
    "max_depths = [2, 3, 5, 7]\n",
    "num_leaves_opts = [2 ** i for i in max_depths]\n",
    "min_data_in_leaf_opts = [250, 500, 1000]\n",
    "\n",
    "# weight of each new tree in the ensemble\n",
    "learning_rate_ops = [.01, .1, .3]\n",
    "\n",
    "# random feature selection\n",
    "feature_fraction_opts = [.3, .6, .95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.960258Z",
     "start_time": "2020-06-21T03:19:37.953744Z"
    }
   },
   "outputs": [],
   "source": [
    "param_names = ['learning_rate', 'num_leaves',\n",
    "               'feature_fraction', 'min_data_in_leaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.969006Z",
     "start_time": "2020-06-21T03:19:37.961383Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Parameters: 108\n"
     ]
    }
   ],
   "source": [
    "cv_params = list(product(learning_rate_ops,\n",
    "                         num_leaves_opts,\n",
    "                         feature_fraction_opts,\n",
    "                         min_data_in_leaf_opts))\n",
    "n_params = len(cv_params)\n",
    "print(f'# Parameters: {n_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Period Lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.977749Z",
     "start_time": "2020-06-21T03:19:37.969903Z"
    }
   },
   "outputs": [],
   "source": [
    "lookaheads = [1, 5, 21]\n",
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only use test periods of 63 days length to save some model training and evaluation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.986465Z",
     "start_time": "2020-06-21T03:19:37.978744Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lengths = [int(4.5 * 253), 253]\n",
    "test_lengths = [63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:37.995277Z",
     "start_time": "2020-06-21T03:19:37.987379Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train configs: 6\n"
     ]
    }
   ],
   "source": [
    "test_params = list(product(lookaheads, train_lengths, test_lengths))\n",
    "n = len(test_params)\n",
    "test_param_sample = np.random.choice(list(range(n)), size=int(n), replace=False)\n",
    "test_params = [test_params[i] for i in test_param_sample]\n",
    "print('Train configs:', len(test_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We integer-encode categorical variables with values starting at zero, as expected by LightGBM (not necessary\n",
    "as long as the category codes have values less than $2^{32}$, but avoids a warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.043537Z",
     "start_time": "2020-06-21T03:19:37.996178Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categoricals = ['year', 'weekday', 'month']\n",
    "for feature in categoricals:\n",
    "    data[feature] = pd.factorize(data[feature], sort=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function: Information Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.046578Z",
     "start_time": "2020-06-21T03:19:38.044405Z"
    }
   },
   "outputs": [],
   "source": [
    "def ic_lgbm(preds, train_data):\n",
    "    \"\"\"Custom IC eval metric for lightgbm\"\"\"\n",
    "    is_higher_better = True\n",
    "    return 'ic', spearmanr(preds, train_data.get_label())[0], is_higher_better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To explore the hyperparameter space, we specify values for key parameters that we would like to test in combination. The sklearn library supports `RandomizedSearchCV` to cross-validate a subset of parameter combinations that are sampled randomly from specified distributions. We will implement a custom version that allows us to monitor performance so we can abort the search process once we're satisfied with the result, rather than specifying a set number of iterations beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.054547Z",
     "start_time": "2020-06-21T03:19:38.047670Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_store = Path(results_path / 'tuning_lgb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.070171Z",
     "start_time": "2020-06-21T03:19:38.055637Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = sorted(data.filter(like='fwd').columns)\n",
    "features = data.columns.difference(labels).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.078077Z",
     "start_time": "2020-06-21T03:19:38.071079Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_dict = dict(zip(lookaheads, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.086476Z",
     "start_time": "2020-06-21T03:19:38.078921Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_iterations = [10, 25, 50, 75] + list(range(100, 501, 50))\n",
    "num_boost_round = num_iterations[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T03:19:38.094204Z",
     "start_time": "2020-06-21T03:19:38.087354Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_cols = (param_names + ['t', 'daily_ic_mean', 'daily_ic_mean_n',\n",
    "                              'daily_ic_median', 'daily_ic_median_n'] +\n",
    "               [str(n) for n in num_iterations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate over our six cross validation configurations and collect the resulting metrics (testing in order to see which hyperparameters for our ML algorithim work best):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T11:56:42.000694Z",
     "start_time": "2020-06-21T03:19:38.095078Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookahead:  1 | Train: 253 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:45 ( 45) |  0.10 |  32 | 95% |  500 |  -4.27% |  0.94% |  250 |  0.77% |  500\n",
      "\t  1 | 00:01:15 ( 30) |  0.01 |   4 | 60% |  250 |  -3.28% |  0.78% |  500 |  1.70% |  500\n",
      "\t  2 | 00:02:01 ( 46) |  0.10 |  32 | 60% |  500 |  -3.74% |  0.95% |   10 |  1.06% |   25\n",
      "\t  3 | 00:02:30 ( 29) |  0.30 |   4 | 60% |  500 |  -2.70% |  0.91% |   50 |  1.50% |   25\n",
      "\t  4 | 00:02:59 ( 29) |  0.10 |   4 | 60% |  250 |  -2.91% |  1.06% |   75 |  1.36% |   75\n",
      "\t  5 | 00:03:50 ( 51) |  0.01 |  32 | 60% |  500 |  -4.03% |  0.99% |   10 |  0.85% |   10\n",
      "\t  6 | 00:05:38 (108) |  0.10 | 128 | 60% | 1000 |  -3.33% |  1.14% |   10 |  0.95% |  200\n",
      "\t  7 | 00:06:58 ( 80) |  0.10 | 128 | 30% | 1000 |  -3.24% |  1.14% |   75 |  1.37% |  500\n",
      "\t  8 | 00:08:15 ( 77) |  0.01 | 128 | 95% |  250 |  -3.84% |  0.53% |  500 |  0.63% |  500\n",
      "\t  9 | 00:08:45 ( 30) |  0.01 |   4 | 95% |  250 |  -2.48% |  0.79% |  500 |  1.32% |  400\n",
      "\t 10 | 00:09:18 ( 33) |  0.30 |   8 | 60% |  500 |  -2.69% |  1.18% |  500 |  1.61% |   25\n",
      "\t 11 | 00:10:39 ( 81) |  0.30 | 128 | 95% |  250 |  -3.19% |  0.56% |  150 |  0.81% |  100\n",
      "\t 12 | 00:11:30 ( 52) |  0.30 |  32 | 95% | 1000 |  -3.37% |  0.77% |  150 |  0.86% |  400\n",
      "\t 13 | 00:12:05 ( 34) |  0.30 |  32 | 30% |  500 |  -2.97% |  1.11% |  400 |  0.54% |   10\n",
      "\t 14 | 00:12:45 ( 40) |  0.30 |  32 | 60% |  500 |  -3.56% |  1.29% |   25 |  1.29% |  350\n",
      "\t 15 | 00:13:08 ( 23) |  0.10 |   4 | 30% | 1000 |  -3.08% |  0.98% |  100 |  1.42% |   75\n",
      "\t 16 | 00:13:36 ( 28) |  0.30 |   8 | 95% |  250 |  -3.69% |  0.77% |  400 |  1.00% |  400\n",
      "\t 17 | 00:14:06 ( 30) |  0.10 |   8 | 60% | 1000 |  -3.27% |  1.11% |   50 |  1.47% |   25\n",
      "\t 18 | 00:14:32 ( 26) |  0.30 |   4 | 60% | 1000 |  -2.96% |  1.02% |  450 |  1.16% |   25\n",
      "\t 19 | 00:14:55 ( 23) |  0.30 |   4 | 30% |  250 |  -3.26% |  1.01% |  450 |  0.92% |   10\n",
      "\t 20 | 00:15:22 ( 26) |  0.30 |   4 | 95% | 1000 |  -3.07% |  0.74% |  400 |  0.97% |  350\n",
      "\t 21 | 00:15:48 ( 26) |  0.30 |   4 | 95% |  250 |  -3.22% |  0.77% |  500 |  1.27% |  500\n",
      "\t 22 | 00:16:14 ( 26) |  0.10 |   4 | 60% | 1000 |  -3.33% |  0.98% |   75 |  1.24% |  100\n",
      "\t 23 | 00:16:57 ( 43) |  0.10 |  32 | 95% | 1000 |  -4.18% |  0.99% |  500 |  0.90% |  500\n",
      "\t 24 | 00:17:26 ( 29) |  0.30 |   8 | 60% | 1000 |  -2.98% |  0.98% |   10 |  1.09% |  500\n",
      "\t 25 | 00:18:48 ( 82) |  0.10 | 128 | 60% |  500 |  -3.44% |  0.98% |  500 |  1.29% |  500\n",
      "\t 26 | 00:19:17 ( 29) |  0.10 |   8 | 95% |  250 |  -3.87% |  0.52% |   75 |  0.85% |   50\n",
      "\t 27 | 00:20:28 ( 72) |  0.10 | 128 | 60% |  250 |  -3.60% |  1.14% |  300 |  1.47% |  250\n",
      "\t 28 | 00:21:12 ( 44) |  0.01 |  32 | 60% |  250 |  -3.93% |  0.94% |  500 |  0.97% |  100\n",
      "\t 29 | 00:21:39 ( 26) |  0.10 |   4 | 95% |  250 |  -3.34% |  0.86% |   75 |  1.05% |  250\n",
      "\t 30 | 00:22:03 ( 25) |  0.30 |   8 | 30% | 1000 |  -3.14% |  1.16% |  400 |  1.21% |  400\n",
      "\t 31 | 00:22:45 ( 41) |  0.01 |  32 | 95% |  500 |  -3.94% |  0.57% |  450 |  0.93% |  400\n",
      "\t 32 | 00:23:20 ( 35) |  0.30 |  32 | 95% |  250 |  -3.56% |  0.68% |  200 |  1.11% |  500\n",
      "\t 33 | 00:23:45 ( 26) |  0.01 |   8 | 30% |  500 |  -3.55% |  1.05% |  450 |  1.16% |  500\n",
      "\t 34 | 00:24:48 ( 63) |  0.30 | 128 | 30% |  500 |  -2.54% |  0.93% |  100 |  1.20% |  300\n",
      "\t 35 | 00:25:42 ( 54) |  0.30 | 128 | 30% |  250 |  -3.04% |  1.18% |   75 |  1.19% |   75\n",
      "\t 36 | 00:26:07 ( 25) |  0.30 |   8 | 30% |  500 |  -3.12% |  1.22% |  500 |  1.05% |  300\n",
      "\t 37 | 00:27:36 ( 89) |  0.30 | 128 | 95% | 1000 |  -3.07% |  0.61% |   10 |  0.67% |  350\n",
      "\t 38 | 00:28:43 ( 67) |  0.30 | 128 | 60% |  250 |  -2.88% |  1.11% |   10 |  0.98% |   25\n",
      "\t 39 | 00:29:46 ( 63) |  0.01 | 128 | 30% | 1000 |  -3.92% |  1.28% |  500 |  1.68% |  350\n",
      "\t 40 | 00:30:12 ( 26) |  0.01 |   8 | 30% |  250 |  -3.63% |  1.00% |  450 |  1.07% |  200\n",
      "\t 41 | 00:30:34 ( 23) |  0.01 |   4 | 30% |  500 |  -3.41% |  0.88% |  500 |  1.11% |  500\n",
      "\t 42 | 00:31:16 ( 42) |  0.01 |  32 | 95% |  250 |  -3.96% |  0.66% |  400 |  0.80% |  150\n",
      "\t 43 | 00:31:42 ( 26) |  0.01 |   4 | 60% |  500 |  -3.19% |  0.79% |  500 |  1.45% |  400\n",
      "\t 44 | 00:32:10 ( 28) |  0.30 |   8 | 95% |  500 |  -4.28% |  1.05% |  450 |  0.97% |  450\n",
      "\t 45 | 00:33:36 ( 86) |  0.30 | 128 | 60% | 1000 |  -2.91% |  0.93% |   10 |  1.03% |   25\n",
      "\t 46 | 00:34:44 ( 68) |  0.01 | 128 | 95% |  500 |  -4.00% |  0.49% |  500 |  0.38% |   25\n",
      "\t 47 | 00:35:08 ( 25) |  0.10 |   8 | 30% |  250 |  -3.35% |  1.03% |  400 |  1.24% |  300\n",
      "\t 48 | 00:35:41 ( 32) |  0.10 |  32 | 30% |  250 |  -3.51% |  1.08% |  100 |  0.81% |   50\n",
      "\t 49 | 00:36:44 ( 63) |  0.01 | 128 | 30% |  500 |  -3.97% |  1.39% |  500 |  1.67% |  400\n",
      "\t 50 | 00:37:09 ( 26) |  0.10 |   8 | 30% | 1000 |  -3.66% |  1.15% |  500 |  1.36% |  500\n",
      "\t 51 | 00:38:05 ( 56) |  0.10 | 128 | 30% |  250 |  -3.27% |  1.01% |   50 |  0.90% |  350\n",
      "\t 52 | 00:38:35 ( 30) |  0.01 |   8 | 60% |  250 |  -3.46% |  0.89% |  450 |  1.49% |  400\n",
      "\t 53 | 00:39:07 ( 32) |  0.30 |  32 | 30% |  250 |  -3.56% |  1.05% |   75 |  1.10% |  150\n",
      "Lookahead:  5 | Train: 253 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:29 ( 29) |  0.10 |   8 | 60% |  250 |  -4.75% |  1.71% |  250 |  2.39% |  100\n",
      "\t  1 | 00:01:38 ( 69) |  0.10 | 128 | 60% |  250 |  -3.80% |  1.69% |   10 |  1.69% |   10\n",
      "\t  2 | 00:02:04 ( 25) |  0.10 |   4 | 60% |  250 |  -4.98% |  1.88% |  300 |  2.40% |  250\n",
      "\t  3 | 00:02:31 ( 28) |  0.30 |   8 | 60% |  500 |  -4.09% |  1.48% |  200 |  2.05% |  200\n",
      "\t  4 | 00:03:51 ( 80) |  0.10 | 128 | 60% |  500 |  -3.86% |  1.51% |   10 |  1.99% |   50\n",
      "\t  5 | 00:04:25 ( 33) |  0.10 |  32 | 30% |  250 |  -4.25% |  1.80% |   10 |  1.96% |   50\n",
      "\t  6 | 00:04:50 ( 25) |  0.10 |   4 | 60% |  500 |  -5.11% |  1.84% |  250 |  2.42% |  450\n",
      "\t  7 | 00:05:16 ( 26) |  0.01 |   4 | 95% |  250 |  -7.19% |  1.79% |  350 |  2.19% |  350\n",
      "\t  8 | 00:05:42 ( 25) |  0.10 |   4 | 60% | 1000 |  -5.14% |  1.89% |  250 |  2.45% |  200\n",
      "\t  9 | 00:06:22 ( 40) |  0.10 |  32 | 60% |  500 |  -4.17% |  1.63% |   25 |  2.12% |   25\n",
      "\t 10 | 00:06:52 ( 30) |  0.01 |   8 | 60% | 1000 |  -7.19% |  1.82% |  400 |  2.30% |  200\n",
      "\t 11 | 00:08:07 ( 75) |  0.01 | 128 | 60% | 1000 |  -5.41% |  1.78% |   50 |  2.38% |   25\n",
      "\t 12 | 00:08:48 ( 41) |  0.30 |  32 | 60% | 1000 |  -3.67% |  1.50% |   10 |  1.52% |   10\n",
      "\t 13 | 00:09:14 ( 26) |  0.30 |   4 | 95% |  500 |  -4.06% |  1.82% |   75 |  2.54% |   75\n",
      "\t 14 | 00:10:46 ( 92) |  0.30 | 128 | 60% |  500 |  -3.06% |  1.34% |   10 |  1.40% |   10\n",
      "\t 15 | 00:11:17 ( 31) |  0.30 |   8 | 95% |  250 |  -4.23% |  1.43% |   50 |  1.90% |   50\n",
      "\t 16 | 00:11:47 ( 29) |  0.01 |   4 | 95% | 1000 |  -7.20% |  1.78% |  500 |  2.22% |  350\n",
      "\t 17 | 00:12:12 ( 25) |  0.10 |   4 | 30% |  250 |  -4.42% |  2.28% |  400 |  2.83% |  400\n",
      "\t 18 | 00:13:22 ( 70) |  0.30 | 128 | 95% |  250 |  -2.89% |  1.06% |   75 |  2.07% |   10\n",
      "\t 19 | 00:13:54 ( 32) |  0.30 |   8 | 60% | 1000 |  -4.53% |  1.26% |   10 |  1.53% |  100\n",
      "\t 20 | 00:15:20 ( 86) |  0.30 | 128 | 95% | 1000 |  -2.81% |  1.37% |   25 |  1.87% |   10\n",
      "\t 21 | 00:16:08 ( 48) |  0.01 |  32 | 60% |  250 |  -6.04% |  1.64% |   25 |  1.80% |  450\n",
      "\t 22 | 00:16:36 ( 28) |  0.30 |   8 | 30% | 1000 |  -4.16% |  1.90% |   75 |  1.76% |   75\n",
      "\t 23 | 00:17:03 ( 27) |  0.30 |   8 | 30% |  250 |  -4.17% |  1.76% |   10 |  2.00% |  100\n",
      "\t 24 | 00:17:34 ( 32) |  0.10 |   8 | 95% |  500 |  -4.69% |  1.48% |  100 |  1.81% |   50\n",
      "\t 25 | 00:18:16 ( 42) |  0.01 |  32 | 30% | 1000 |  -6.64% |  2.02% |  250 |  2.47% |  250\n",
      "\t 26 | 00:19:25 ( 69) |  0.01 | 128 | 30% |  250 |  -6.26% |  1.98% |  150 |  2.35% |  200\n",
      "\t 27 | 00:20:05 ( 40) |  0.01 |  32 | 30% |  250 |  -6.53% |  2.08% |  250 |  2.33% |  150\n",
      "\t 28 | 00:20:45 ( 40) |  0.30 |  32 | 30% | 1000 |  -3.78% |  1.83% |   10 |  1.81% |   10\n",
      "\t 29 | 00:22:14 ( 89) |  0.01 | 128 | 95% |  500 |  -4.57% |  1.03% |   75 |  1.78% |  350\n",
      "\t 30 | 00:22:46 ( 32) |  0.01 |   8 | 95% | 1000 |  -6.94% |  1.29% |  200 |  1.92% |  150\n",
      "\t 31 | 00:23:51 ( 66) |  0.30 | 128 | 30% |  500 |  -3.49% |  1.46% |   10 |  1.49% |   10\n",
      "\t 32 | 00:24:37 ( 46) |  0.01 |  32 | 95% | 1000 |  -5.54% |  1.02% |   25 |  1.23% |   25\n",
      "\t 33 | 00:25:59 ( 83) |  0.01 | 128 | 95% | 1000 |  -4.59% |  1.09% |   75 |  1.70% |  350\n",
      "\t 34 | 00:26:42 ( 43) |  0.30 |  32 | 95% | 1000 |  -3.71% |  0.81% |   25 |  1.82% |   25\n",
      "\t 35 | 00:27:12 ( 30) |  0.30 |   8 | 95% | 1000 |  -3.90% |  1.57% |  150 |  1.99% |   25\n",
      "\t 36 | 00:27:58 ( 46) |  0.01 |  32 | 95% |  250 |  -5.73% |  0.99% |   50 |  1.10% |  450\n",
      "\t 37 | 00:28:37 ( 39) |  0.30 |  32 | 60% |  250 |  -3.83% |  1.38% |   10 |  1.63% |   10\n",
      "\t 38 | 00:29:16 ( 39) |  0.10 |  32 | 95% |  250 |  -3.88% |  1.19% |   25 |  1.79% |  200\n",
      "\t 39 | 00:29:43 ( 27) |  0.01 |   4 | 95% |  500 |  -7.17% |  1.79% |  500 |  2.15% |  500\n",
      "\t 40 | 00:30:10 ( 27) |  0.10 |   4 | 95% |  500 |  -4.67% |  2.09% |   50 |  2.62% |  250\n",
      "\t 41 | 00:30:35 ( 26) |  0.10 |   8 | 30% |  250 |  -4.68% |  1.93% |   75 |  2.42% |  100\n",
      "\t 42 | 00:31:54 ( 78) |  0.01 | 128 | 60% |  250 |  -5.14% |  1.71% |   25 |  1.80% |  400\n",
      "\t 43 | 00:32:24 ( 31) |  0.01 |   8 | 95% |  250 |  -7.12% |  1.30% |  400 |  2.01% |  150\n",
      "\t 44 | 00:32:52 ( 27) |  0.30 |   4 | 95% | 1000 |  -4.46% |  1.92% |  250 |  2.66% |  150\n",
      "\t 45 | 00:33:17 ( 26) |  0.01 |   8 | 30% |  500 |  -6.63% |  2.08% |  450 |  2.31% |  450\n",
      "\t 46 | 00:33:43 ( 26) |  0.10 |   8 | 30% | 1000 |  -4.88% |  1.86% |   50 |  2.31% |   50\n",
      "\t 47 | 00:34:09 ( 26) |  0.10 |   4 | 95% |  250 |  -4.79% |  1.83% |  450 |  2.54% |   25\n",
      "\t 48 | 00:34:39 ( 30) |  0.01 |   8 | 60% |  250 |  -7.10% |  1.80% |  300 |  2.28% |  500\n",
      "\t 49 | 00:35:01 ( 23) |  0.01 |   4 | 30% |  500 |  -7.11% |  2.01% |  450 |  1.86% |  400\n",
      "\t 50 | 00:35:27 ( 26) |  0.01 |   4 | 60% | 1000 |  -6.93% |  1.89% |  500 |  1.93% |  500\n",
      "\t 51 | 00:36:03 ( 36) |  0.30 |  32 | 95% |  250 |  -3.22% |  1.21% |   25 |  1.69% |   25\n",
      "\t 52 | 00:37:29 ( 86) |  0.10 | 128 | 60% | 1000 |  -3.81% |  1.47% |   10 |  1.44% |   10\n",
      "\t 53 | 00:38:13 ( 44) |  0.01 |  32 | 60% | 1000 |  -6.08% |  1.66% |   25 |  1.70% |   50\n",
      "Lookahead: 21 | Train: 1138 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:01:07 ( 67) |  0.10 |   8 | 95% | 1000 |   3.04% |  9.30% |  450 |  9.27% |  400\n",
      "\t  1 | 00:02:04 ( 57) |  0.10 |   8 | 30% | 1000 |   2.52% |  9.42% |  500 |  9.67% |  350\n",
      "\t  2 | 00:03:20 ( 75) |  0.01 |   8 | 95% |  250 |  -0.87% |  8.35% |  500 |  8.70% |  500\n",
      "\t  3 | 00:06:01 (161) |  0.01 | 128 | 95% |  500 |   8.15% |  10.21% |  500 |  10.23% |  450\n",
      "\t  4 | 00:07:18 ( 77) |  0.30 |  32 | 60% |  500 |   6.74% |  8.81% |  100 |  8.92% |  150\n",
      "\t  5 | 00:09:18 (120) |  0.10 | 128 | 95% |  250 |   8.84% |  10.03% |   50 |  10.06% |   75\n",
      "\t  6 | 00:10:35 ( 76) |  0.30 |  32 | 60% |  250 |   8.40% |  8.51% |  100 |  8.27% |   50\n",
      "\t  7 | 00:12:23 (108) |  0.30 | 128 | 95% |  250 |   8.85% |  8.02% |   10 |  8.00% |   10\n",
      "\t  8 | 00:14:29 (126) |  0.10 | 128 | 95% |  500 |   8.29% |  9.65% |   50 |  9.65% |   50\n",
      "\t  9 | 00:15:26 ( 58) |  0.30 |   8 | 30% |  500 |   7.04% |  10.08% |  250 |  10.03% |  250\n",
      "\t 10 | 00:17:03 ( 97) |  0.10 |  32 | 60% | 1000 |   8.75% |  10.13% |  250 |  10.41% |  250\n",
      "\t 11 | 00:18:27 ( 84) |  0.30 |  32 | 95% |  250 |   4.83% |  8.10% |  250 |  8.29% |  150\n",
      "\t 12 | 00:21:02 (155) |  0.10 | 128 | 60% | 1000 |   5.85% |  9.31% |  100 |  9.34% |   75\n",
      "\t 13 | 00:22:15 ( 73) |  0.30 |   8 | 60% |  250 |   7.28% |  9.53% |   75 |  9.64% |  150\n",
      "\t 14 | 00:23:29 ( 74) |  0.01 |   4 | 60% |  500 |  -2.40% |  6.97% |  500 |  6.57% |  450\n",
      "\t 15 | 00:24:41 ( 72) |  0.01 |   8 | 30% | 1000 |   1.87% |  7.61% |  500 |  7.94% |  450\n",
      "\t 16 | 00:27:20 (159) |  0.10 | 128 | 95% | 1000 |   8.00% |  9.82% |  100 |  9.66% |  100\n",
      "\t 17 | 00:29:25 (125) |  0.10 | 128 | 30% |  500 |   4.74% |  8.86% |  250 |  9.00% |   75\n",
      "\t 18 | 00:31:45 (140) |  0.01 | 128 | 30% |  500 |   0.67% |  9.41% |  500 |  9.89% |  500\n",
      "\t 19 | 00:33:60 (135) |  0.01 |  32 | 95% | 1000 |   6.67% |  9.49% |  500 |  10.27% |  500\n",
      "\t 20 | 00:37:08 (188) |  0.01 | 128 | 60% |  500 |   4.10% |  10.04% |  500 |  10.18% |  500\n",
      "\t 21 | 00:38:48 (100) |  0.10 |  32 | 95% |  250 |   6.23% |  9.02% |  250 |  9.32% |  250\n",
      "\t 22 | 00:40:12 ( 84) |  0.10 |  32 | 30% |  250 |   5.67% |  9.76% |  300 |  10.12% |  300\n",
      "\t 23 | 00:41:15 ( 62) |  0.30 |   4 | 30% |  250 |   2.40% |  9.17% |  250 |  9.40% |  250\n",
      "\t 24 | 00:43:17 (122) |  0.10 |  32 | 95% | 1000 |   7.31% |  9.51% |  150 |  9.80% |  250\n",
      "\t 25 | 00:44:40 ( 83) |  0.10 |   8 | 60% |  500 |   4.53% |  9.39% |  500 |  9.54% |  300\n",
      "\t 26 | 00:45:45 ( 65) |  0.30 |   8 | 30% |  250 |   3.03% |  9.43% |  200 |  9.20% |  400\n",
      "\t 27 | 00:47:06 ( 81) |  0.10 |   8 | 95% |  500 |   4.11% |  9.43% |  450 |  9.65% |  200\n",
      "\t 28 | 00:48:18 ( 73) |  0.10 |   4 | 95% |  250 |   2.64% |  8.70% |  450 |  9.21% |  500\n",
      "\t 29 | 00:49:32 ( 74) |  0.30 |   4 | 95% |  500 |   3.52% |  9.73% |  450 |  10.30% |  400\n",
      "\t 30 | 00:51:09 ( 97) |  0.01 |  32 | 30% |  500 |   1.35% |  8.91% |  500 |  8.84% |  500\n",
      "\t 31 | 00:52:17 ( 68) |  0.30 |  32 | 30% |  500 |   3.74% |  7.80% |  100 |  7.80% |  100\n",
      "\t 32 | 00:53:16 ( 59) |  0.10 |   8 | 30% |  250 |   1.46% |  9.78% |  500 |  9.77% |  500\n",
      "\t 33 | 00:54:29 ( 72) |  0.10 |   8 | 60% | 1000 |   4.18% |  9.25% |  450 |  9.53% |  450\n",
      "\t 34 | 00:55:33 ( 64) |  0.30 |   4 | 95% | 1000 |   6.06% |  9.36% |  400 |  9.39% |  450\n",
      "\t 35 | 00:57:28 (115) |  0.30 | 128 | 95% |  500 |   8.49% |  8.16% |   25 |  7.51% |   25\n",
      "\t 36 | 00:58:37 ( 69) |  0.30 |   8 | 95% |  500 |   4.34% |  8.77% |  300 |  8.94% |  300\n",
      "\t 37 | 01:00:37 (121) |  0.30 | 128 | 60% |  500 |   8.63% |  8.25% |   75 |  8.06% |   50\n",
      "\t 38 | 01:01:44 ( 67) |  0.01 |   4 | 95% | 1000 |  -1.43% |  7.31% |  500 |  6.89% |  500\n",
      "\t 39 | 01:03:23 ( 99) |  0.01 |  32 | 60% | 1000 |   3.78% |  9.67% |  500 |  9.77% |  500\n",
      "\t 40 | 01:05:45 (142) |  0.01 | 128 | 60% |  250 |   4.65% |  10.01% |  500 |  10.05% |  500\n",
      "\t 41 | 01:07:07 ( 82) |  0.10 |  32 | 95% |  500 |   8.11% |  9.11% |  300 |  9.67% |  350\n",
      "\t 42 | 01:08:08 ( 61) |  0.01 |   8 | 30% |  500 |   1.88% |  7.65% |  500 |  7.95% |  500\n",
      "\t 43 | 01:10:01 (113) |  0.01 | 128 | 30% | 1000 |   0.71% |  9.21% |  500 |  9.77% |  500\n",
      "\t 44 | 01:11:06 ( 66) |  0.01 |   4 | 60% |  250 |  -2.40% |  6.95% |  500 |  6.62% |  500\n",
      "\t 45 | 01:12:38 ( 92) |  0.30 | 128 | 30% |  500 |   4.28% |  7.83% |   50 |  8.02% |   25\n",
      "\t 46 | 01:13:45 ( 67) |  0.30 |  32 | 30% | 1000 |  10.29% |  8.28% |   50 |  8.56% |  100\n",
      "\t 47 | 01:15:02 ( 77) |  0.01 |  32 | 30% | 1000 |   0.78% |  8.84% |  500 |  8.82% |  500\n",
      "\t 48 | 01:16:40 ( 97) |  0.01 |  32 | 60% |  250 |   3.84% |  9.58% |  500 |  9.62% |  450\n",
      "\t 49 | 01:19:08 (148) |  0.01 | 128 | 60% | 1000 |   4.39% |  10.00% |  500 |  10.31% |  500\n",
      "\t 50 | 01:20:29 ( 81) |  0.10 |  32 | 60% |  250 |   7.95% |  9.66% |  250 |  9.99% |  150\n",
      "\t 51 | 01:21:30 ( 62) |  0.30 |   4 | 60% |  500 |   2.56% |  9.33% |  500 |  9.66% |  400\n",
      "\t 52 | 01:22:30 ( 60) |  0.10 |   4 | 95% | 1000 |   2.33% |  9.12% |  500 |  9.06% |  500\n",
      "\t 53 | 01:24:14 (104) |  0.10 | 128 | 30% | 1000 |   1.43% |  8.54% |  100 |  9.08% |  100\n",
      "Lookahead:  5 | Train: 1138 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:01:48 (108) |  0.01 | 128 | 30% |  250 |  -3.31% |  3.42% |  500 |  3.86% |  500\n",
      "\t  1 | 00:02:59 ( 71) |  0.01 |   8 | 95% |  250 |  -2.79% |  3.38% |  500 |  3.11% |  500\n",
      "\t  2 | 00:05:15 (136) |  0.10 | 128 | 95% | 1000 |   0.10% |  2.93% |  200 |  2.77% |  200\n",
      "\t  3 | 00:06:34 ( 79) |  0.10 |  32 | 30% | 1000 |  -3.60% |  3.64% |  400 |  4.02% |   75\n",
      "\t  4 | 00:08:32 (118) |  0.01 |  32 | 95% | 1000 |  -3.84% |  3.31% |  350 |  3.40% |  350\n",
      "\t  5 | 00:09:37 ( 65) |  0.01 |   8 | 30% | 1000 |  -5.30% |  3.29% |  500 |  3.16% |  450\n",
      "\t  6 | 00:10:48 ( 71) |  0.30 |   8 | 60% |  250 |  -2.33% |  3.01% |   25 |  3.48% |   75\n",
      "\t  7 | 00:12:01 ( 73) |  0.10 |   8 | 95% |  500 |  -1.94% |  3.44% |  100 |  3.77% |  200\n",
      "\t  8 | 00:13:32 ( 90) |  0.10 |  32 | 95% |  250 |  -1.03% |  3.11% |  150 |  3.43% |   50\n",
      "\t  9 | 00:14:36 ( 65) |  0.30 |   4 | 95% |  250 |   0.37% |  3.30% |  450 |  3.26% |  450\n",
      "\t 10 | 00:15:46 ( 69) |  0.30 |  32 | 30% |  250 |  -2.15% |  3.07% |   75 |  3.32% |  100\n",
      "\t 11 | 00:18:24 (158) |  0.01 | 128 | 60% |  250 |  -2.56% |  3.21% |  500 |  3.47% |  400\n",
      "\t 12 | 00:20:16 (112) |  0.30 | 128 | 30% | 1000 |  -0.72% |  2.48% |   50 |  2.24% |   10\n",
      "\t 13 | 00:21:39 ( 83) |  0.30 |  32 | 60% |  250 |  -0.44% |  2.92% |   25 |  3.32% |   10\n",
      "\t 14 | 00:22:44 ( 65) |  0.30 |   4 | 95% |  500 |  -0.22% |  2.74% |   25 |  2.86% |  400\n",
      "\t 15 | 00:23:56 ( 73) |  0.30 |  32 | 30% | 1000 |  -0.32% |  2.67% |  250 |  2.97% |   50\n",
      "\t 16 | 00:25:53 (117) |  0.10 | 128 | 30% | 1000 |  -1.56% |  3.18% |  300 |  3.51% |  300\n",
      "\t 17 | 00:27:36 (103) |  0.30 | 128 | 30% |  500 |   1.02% |  2.84% |   75 |  2.62% |   75\n",
      "\t 18 | 00:28:60 ( 84) |  0.01 |  32 | 30% |  500 |  -3.77% |  3.64% |  500 |  3.86% |  450\n",
      "\t 19 | 00:30:27 ( 87) |  0.30 |  32 | 95% | 1000 |  -0.51% |  3.23% |   50 |  3.42% |   50\n",
      "\t 20 | 00:31:38 ( 71) |  0.30 |   8 | 60% |  500 |  -0.15% |  3.60% |   50 |  3.80% |   25\n",
      "\t 21 | 00:32:45 ( 67) |  0.01 |   4 | 95% |  250 |  -4.11% |  2.86% |  400 |  2.65% |  400\n",
      "\t 22 | 00:33:56 ( 71) |  0.10 |   8 | 95% |  250 |  -2.06% |  3.29% |   50 |  3.53% |  500\n",
      "\t 23 | 00:36:10 (134) |  0.10 | 128 | 95% |  500 |  -0.28% |  2.84% |  250 |  3.15% |   75\n",
      "\t 24 | 00:37:13 ( 62) |  0.10 |   8 | 30% |  250 |  -4.55% |  3.90% |  500 |  4.29% |  500\n",
      "\t 25 | 00:38:23 ( 70) |  0.10 |  32 | 30% |  250 |  -3.84% |  3.93% |  350 |  4.17% |  350\n",
      "\t 26 | 00:39:33 ( 70) |  0.30 |   8 | 60% | 1000 |  -1.95% |  3.51% |   25 |  3.29% |   25\n",
      "\t 27 | 00:40:40 ( 67) |  0.30 |   8 | 95% |  500 |  -0.52% |  3.06% |  500 |  3.14% |  500\n",
      "\t 28 | 00:43:31 (172) |  0.01 | 128 | 95% | 1000 |  -1.36% |  2.77% |  500 |  3.01% |  400\n",
      "\t 29 | 00:44:43 ( 72) |  0.10 |  32 | 30% |  500 |  -3.06% |  3.60% |  150 |  4.13% |  100\n",
      "\t 30 | 00:45:49 ( 66) |  0.30 |   4 | 60% |  250 |  -1.60% |  3.13% |   25 |  3.19% |   75\n",
      "\t 31 | 00:46:56 ( 67) |  0.30 |   8 | 95% |  250 |  -0.76% |  3.05% |  300 |  3.29% |  100\n",
      "\t 32 | 00:47:53 ( 57) |  0.10 |   8 | 30% |  500 |  -4.14% |  3.86% |  300 |  4.25% |  350\n",
      "\t 33 | 00:48:58 ( 65) |  0.10 |   8 | 95% | 1000 |  -1.39% |  3.37% |   75 |  3.67% |  100\n",
      "\t 34 | 00:49:57 ( 60) |  0.30 |   4 | 95% | 1000 |  -1.54% |  3.36% |  450 |  3.22% |  250\n",
      "\t 35 | 00:51:15 ( 78) |  0.30 |  32 | 60% |  500 |   0.51% |  2.93% |  100 |  3.54% |  100\n",
      "\t 36 | 00:53:01 (107) |  0.30 | 128 | 60% |  250 |   0.13% |  2.35% |   10 |  2.07% |   50\n",
      "\t 37 | 00:55:27 (146) |  0.01 | 128 | 60% |  500 |  -2.05% |  3.06% |  500 |  3.33% |  500\n",
      "\t 38 | 00:56:34 ( 67) |  0.10 |   8 | 60% | 1000 |   0.17% |  3.52% |  100 |  3.68% |  200\n",
      "\t 39 | 00:57:33 ( 59) |  0.10 |   4 | 95% |  250 |  -2.78% |  3.31% |  100 |  3.54% |  500\n",
      "\t 40 | 00:58:25 ( 52) |  0.10 |   4 | 30% | 1000 |  -3.45% |  3.52% |  350 |  3.67% |  500\n",
      "\t 41 | 00:59:20 ( 55) |  0.30 |   8 | 30% |  250 |   0.25% |  3.55% |  350 |  3.43% |  350\n",
      "\t 42 | 01:01:22 (122) |  0.10 | 128 | 60% |  500 |  -0.67% |  2.92% |  100 |  3.23% |  200\n",
      "\t 43 | 01:02:35 ( 73) |  0.01 |   8 | 95% | 1000 |  -2.92% |  3.32% |  500 |  3.06% |  500\n",
      "\t 44 | 01:03:34 ( 59) |  0.10 |   8 | 30% | 1000 |  -5.15% |  3.76% |  300 |  3.96% |  500\n",
      "\t 45 | 01:04:37 ( 63) |  0.10 |   4 | 60% | 1000 |  -1.37% |  3.36% |  300 |  3.34% |  500\n",
      "\t 46 | 01:05:36 ( 60) |  0.10 |   4 | 95% | 1000 |  -3.40% |  3.33% |  150 |  3.79% |  400\n",
      "\t 47 | 01:07:18 (102) |  0.01 |  32 | 95% |  250 |  -4.07% |  3.31% |  400 |  3.77% |  400\n",
      "\t 48 | 01:08:22 ( 64) |  0.01 |   4 | 60% |  250 |  -5.66% |  2.91% |  500 |  2.45% |  500\n",
      "\t 49 | 01:10:02 (100) |  0.01 |  32 | 95% |  500 |  -3.71% |  3.27% |  350 |  3.58% |  350\n",
      "\t 50 | 01:11:23 ( 81) |  0.10 |  32 | 60% |  250 |  -1.69% |  3.71% |  300 |  3.75% |   75\n",
      "\t 51 | 01:12:38 ( 75) |  0.01 |  32 | 30% |  250 |  -3.98% |  3.59% |  500 |  3.71% |  500\n",
      "\t 52 | 01:13:58 ( 80) |  0.30 |  32 | 60% | 1000 |  -0.44% |  3.12% |   50 |  3.26% |  100\n",
      "\t 53 | 01:15:20 ( 82) |  0.10 |  32 | 60% |  500 |  -1.52% |  3.45% |  150 |  3.77% |  250\n",
      "Lookahead:  1 | Train: 1138 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:01:11 ( 71) |  0.01 |   8 | 95% |  500 |  -4.33% |  0.93% |  500 |  1.16% |  500\n",
      "\t  1 | 00:03:04 (113) |  0.01 | 128 | 30% | 1000 |  -1.52% |  1.62% |  500 |  1.74% |  450\n",
      "\t  2 | 00:04:18 ( 74) |  0.01 |  32 | 30% |  250 |  -1.65% |  1.42% |  500 |  1.53% |  450\n",
      "\t  3 | 00:05:32 ( 75) |  0.30 |  32 | 60% |  250 |  -1.25% |  1.47% |  150 |  1.62% |   75\n",
      "\t  4 | 00:06:52 ( 79) |  0.10 |  32 | 60% |  250 |  -2.23% |  1.47% |  350 |  1.89% |  150\n",
      "\t  5 | 00:08:11 ( 80) |  0.10 |  32 | 60% |  500 |  -2.03% |  1.45% |  450 |  1.59% |  300\n",
      "\t  6 | 00:10:49 (158) |  0.01 | 128 | 95% |  500 |  -2.63% |  0.95% |  500 |  1.18% |  250\n",
      "\t  7 | 00:13:01 (132) |  0.30 | 128 | 95% | 1000 |  -1.92% |  1.20% |   10 |  1.47% |   10\n",
      "\t  8 | 00:14:02 ( 61) |  0.30 |   4 | 60% |  500 |  -2.53% |  1.34% |  350 |  1.80% |  350\n",
      "\t  9 | 00:15:38 ( 96) |  0.01 |  32 | 60% | 1000 |  -2.44% |  1.57% |  500 |  1.45% |  450\n",
      "\t 10 | 00:17:32 (113) |  0.10 | 128 | 60% |  250 |  -1.91% |  1.48% |  450 |  1.24% |  400\n",
      "\t 11 | 00:18:53 ( 81) |  0.10 |  32 | 95% | 1000 |  -2.98% |  1.23% |  500 |  1.29% |  250\n",
      "\t 12 | 00:20:30 ( 97) |  0.10 | 128 | 30% |  500 |  -0.91% |  1.72% |  500 |  1.47% |  200\n",
      "\t 13 | 00:21:39 ( 70) |  0.01 |   8 | 95% |  250 |  -4.46% |  0.80% |  400 |  1.09% |  450\n",
      "\t 14 | 00:22:31 ( 51) |  0.30 |   4 | 30% |  250 |  -1.69% |  1.67% |  250 |  1.94% |  400\n",
      "\t 15 | 00:23:25 ( 55) |  0.30 |   8 | 30% | 1000 |  -1.35% |  1.83% |  500 |  1.81% |  300\n",
      "\t 16 | 00:24:30 ( 64) |  0.30 |   8 | 60% |  250 |  -2.26% |  1.19% |  300 |  1.60% |  300\n",
      "\t 17 | 00:25:41 ( 72) |  0.01 |   8 | 95% | 1000 |  -4.31% |  0.99% |  500 |  1.21% |  400\n",
      "\t 18 | 00:26:42 ( 60) |  0.01 |   4 | 95% |  250 |  -4.31% |  1.66% |   10 |  1.21% |  300\n",
      "\t 19 | 00:27:36 ( 54) |  0.30 |   8 | 30% |  500 |  -0.91% |  1.08% |  450 |  1.41% |  300\n",
      "\t 20 | 00:29:48 (133) |  0.10 | 128 | 95% | 1000 |  -2.72% |  1.38% |  500 |  1.44% |  400\n",
      "\t 21 | 00:31:42 (114) |  0.30 | 128 | 60% |  500 |  -1.02% |  1.18% |   75 |  0.87% |  300\n",
      "\t 22 | 00:32:46 ( 63) |  0.10 |   8 | 95% |  500 |  -3.05% |  1.13% |  300 |  1.31% |   75\n",
      "\t 23 | 00:33:39 ( 53) |  0.01 |   4 | 30% | 1000 |  -3.39% |  0.77% |  450 |  1.19% |  500\n",
      "\t 24 | 00:34:46 ( 67) |  0.10 |   8 | 60% | 1000 |  -2.34% |  1.79% |  350 |  2.17% |  350\n",
      "\t 25 | 00:35:38 ( 52) |  0.10 |   4 | 30% | 1000 |  -2.54% |  1.78% |  450 |  2.12% |  500\n",
      "\t 26 | 00:38:04 (146) |  0.01 | 128 | 60% |  500 |  -2.17% |  1.40% |  500 |  1.19% |  350\n",
      "\t 27 | 00:39:40 ( 96) |  0.01 |  32 | 95% |  250 |  -2.68% |  1.07% |  450 |  0.89% |  100\n",
      "\t 28 | 00:40:32 ( 52) |  0.30 |   4 | 30% | 1000 |  -1.92% |  1.69% |  300 |  1.98% |  450\n",
      "\t 29 | 00:42:18 (106) |  0.30 | 128 | 60% |  250 |  -1.96% |  1.04% |  150 |  1.30% |  200\n",
      "\t 30 | 00:44:16 (118) |  0.30 | 128 | 95% |  500 |  -2.08% |  1.20% |  100 |  1.01% |   50\n",
      "\t 31 | 00:47:06 (171) |  0.01 | 128 | 95% |  250 |  -2.84% |  1.18% |  350 |  1.65% |  350\n",
      "\t 32 | 00:48:19 ( 73) |  0.10 |   8 | 60% |  500 |  -2.31% |  1.80% |  450 |  1.99% |  450\n",
      "\t 33 | 00:50:28 (129) |  0.10 | 128 | 95% |  250 |  -1.87% |  1.29% |  100 |  1.50% |  450\n",
      "\t 34 | 00:51:37 ( 69) |  0.30 |  32 | 30% |  500 |  -1.87% |  1.67% |  100 |  1.71% |  300\n",
      "\t 35 | 00:52:50 ( 73) |  0.10 |   8 | 95% | 1000 |  -2.90% |  1.33% |  500 |  1.80% |  300\n",
      "\t 36 | 00:54:30 (100) |  0.10 | 128 | 30% |  250 |  -1.48% |  1.93% |  450 |  2.13% |  250\n",
      "\t 37 | 00:55:52 ( 83) |  0.10 |  32 | 95% |  250 |  -1.81% |  1.25% |  100 |  1.22% |   75\n",
      "\t 38 | 00:56:55 ( 62) |  0.30 |   4 | 95% |  250 |  -2.37% |  1.43% |  450 |  2.01% |  400\n",
      "\t 39 | 00:58:16 ( 81) |  0.01 |  32 | 30% | 1000 |  -1.88% |  1.48% |  500 |  1.53% |  500\n",
      "\t 40 | 00:59:32 ( 76) |  0.10 |  32 | 30% | 1000 |  -1.98% |  1.91% |  500 |  2.11% |  400\n",
      "\t 41 | 01:00:30 ( 57) |  0.01 |   4 | 30% |  250 |  -3.59% |  0.76% |  150 |  1.10% |  500\n",
      "\t 42 | 01:02:45 (135) |  0.10 | 128 | 95% |  500 |  -2.13% |  1.46% |  400 |  1.34% |  500\n",
      "\t 43 | 01:04:27 (101) |  0.30 | 128 | 30% |  500 |  -1.53% |  1.51% |  100 |  1.55% |   50\n",
      "\t 44 | 01:06:11 (104) |  0.01 |  32 | 60% |  250 |  -2.40% |  1.42% |  500 |  1.21% |  300\n",
      "\t 45 | 01:07:18 ( 67) |  0.10 |   4 | 60% |  500 |  -3.55% |  1.76% |  450 |  2.05% |  450\n",
      "\t 46 | 01:08:25 ( 67) |  0.10 |   4 | 60% |  250 |  -3.48% |  1.59% |  450 |  1.94% |  450\n",
      "\t 47 | 01:09:46 ( 81) |  0.01 |   8 | 60% |  500 |  -3.21% |  0.97% |  500 |  1.44% |  400\n",
      "\t 48 | 01:11:17 ( 91) |  0.30 |  32 | 60% |  500 |  -1.62% |  1.17% |   25 |  1.43% |   25\n",
      "\t 49 | 01:12:22 ( 65) |  0.01 |   4 | 95% | 1000 |  -4.31% |  1.66% |   10 |  1.17% |  200\n",
      "\t 50 | 01:14:07 (106) |  0.30 | 128 | 30% |  250 |  -1.79% |  1.07% |  100 |  0.94% |   10\n",
      "\t 51 | 01:16:13 (126) |  0.01 | 128 | 30% |  250 |  -1.32% |  1.60% |  450 |  1.69% |  500\n",
      "\t 52 | 01:17:28 ( 75) |  0.10 |   8 | 60% |  250 |  -2.88% |  1.54% |  300 |  1.85% |  350\n",
      "\t 53 | 01:18:39 ( 71) |  0.10 |   4 | 60% | 1000 |  -2.87% |  1.50% |  500 |  1.80% |  450\n",
      "Lookahead: 21 | Train: 253 | Test: 63 | Params:  54 | Train configs: 6\n",
      "\t  0 | 00:00:31 ( 31) |  0.01 |   4 | 60% | 1000 |  -11.48% |  7.38% |  500 |  7.40% |  500\n",
      "\t  1 | 00:00:59 ( 28) |  0.10 |   4 | 60% |  500 |  -6.47% |  7.83% |  250 |  8.17% |  300\n",
      "\t  2 | 00:01:28 ( 29) |  0.01 |   4 | 95% | 1000 |  -12.15% |  7.48% |  500 |  7.60% |  500\n",
      "\t  3 | 00:01:57 ( 29) |  0.01 |   8 | 30% | 1000 |  -9.24% |  7.25% |  500 |  7.61% |  250\n",
      "\t  4 | 00:02:26 ( 28) |  0.10 |   8 | 30% | 1000 |  -5.67% |  7.48% |  250 |  7.88% |  150\n",
      "\t  5 | 00:03:50 ( 84) |  0.01 | 128 | 60% |  250 |  -5.86% |  6.74% |  200 |  7.77% |  500\n",
      "\t  6 | 00:04:24 ( 35) |  0.01 |   8 | 60% | 1000 |  -9.62% |  7.06% |  500 |  7.15% |  450\n",
      "\t  7 | 00:04:53 ( 29) |  0.10 |   4 | 95% |  250 |  -5.81% |  7.59% |   75 |  7.51% |  250\n",
      "\t  8 | 00:06:31 ( 98) |  0.30 | 128 | 60% | 1000 |  -4.44% |  5.34% |   10 |  5.01% |   50\n",
      "\t  9 | 00:06:56 ( 25) |  0.01 |   4 | 30% |  500 |  -11.16% |  7.26% |  500 |  7.70% |  500\n",
      "\t 10 | 00:07:47 ( 50) |  0.01 |  32 | 95% | 1000 |  -6.80% |  5.83% |  450 |  7.10% |  500\n",
      "\t 11 | 00:08:18 ( 31) |  0.30 |   8 | 95% |  500 |  -5.58% |  5.69% |   25 |  6.42% |  100\n",
      "\t 12 | 00:08:46 ( 28) |  0.30 |   4 | 60% |  250 |  -3.01% |  7.18% |   50 |  7.01% |   50\n",
      "\t 13 | 00:09:36 ( 50) |  0.01 |  32 | 95% |  250 |  -6.83% |  6.06% |  500 |  7.58% |  500\n",
      "\t 14 | 00:10:11 ( 35) |  0.01 |   8 | 95% |  500 |  -11.04% |  6.60% |  500 |  7.27% |  450\n",
      "\t 15 | 00:10:56 ( 46) |  0.30 |  32 | 60% | 1000 |  -4.74% |  5.43% |   25 |  6.18% |   50\n",
      "\t 16 | 00:11:38 ( 41) |  0.10 |  32 | 30% | 1000 |  -4.91% |  6.95% |  100 |  7.59% |  200\n",
      "\t 17 | 00:12:22 ( 44) |  0.10 |  32 | 60% |  250 |  -4.74% |  6.34% |   25 |  6.75% |  150\n",
      "\t 18 | 00:12:50 ( 29) |  0.30 |   4 | 95% |  500 |  -5.14% |  6.95% |   25 |  7.18% |   75\n",
      "\t 19 | 00:13:16 ( 25) |  0.30 |   4 | 30% |  500 |  -5.97% |  7.66% |  100 |  8.13% |  100\n",
      "\t 20 | 00:14:24 ( 68) |  0.10 | 128 | 95% |  250 |  -4.10% |  5.54% |   25 |  6.20% |   25\n",
      "\t 21 | 00:14:53 ( 29) |  0.30 |   4 | 60% | 1000 |  -3.78% |  7.17% |   50 |  7.23% |   75\n",
      "\t 22 | 00:15:37 ( 43) |  0.01 |  32 | 30% | 1000 |  -7.53% |  7.08% |  250 |  7.48% |  150\n",
      "\t 23 | 00:16:49 ( 72) |  0.30 | 128 | 95% |  250 |  -2.81% |  4.14% |   25 |  5.16% |   10\n",
      "\t 24 | 00:17:19 ( 30) |  0.01 |   4 | 60% |  500 |  -11.84% |  7.51% |  500 |  7.78% |  500\n",
      "\t 25 | 00:17:59 ( 40) |  0.30 |  32 | 95% |  250 |  -3.83% |  5.23% |   25 |  6.05% |   25\n",
      "\t 26 | 00:19:16 ( 77) |  0.10 | 128 | 60% |  250 |  -4.53% |  6.51% |   25 |  7.13% |   50\n",
      "\t 27 | 00:19:50 ( 35) |  0.30 |   4 | 60% |  500 |  -3.97% |  6.85% |   25 |  6.78% |   25\n",
      "\t 28 | 00:20:19 ( 29) |  0.01 |   8 | 30% |  500 |  -9.35% |  7.32% |  500 |  7.57% |  250\n",
      "\t 29 | 00:21:40 ( 81) |  0.01 | 128 | 95% | 1000 |  -5.38% |  5.57% |   75 |  6.36% |  400\n",
      "\t 30 | 00:22:24 ( 44) |  0.30 |  32 | 95% | 1000 |  -4.91% |  4.04% |   75 |  4.93% |   10\n",
      "\t 31 | 00:22:59 ( 35) |  0.01 |   8 | 60% |  500 |  -9.99% |  6.94% |  500 |  7.11% |  500\n",
      "\t 32 | 00:23:29 ( 30) |  0.10 |   4 | 95% |  500 |  -6.24% |  7.69% |  100 |  7.81% |  150\n",
      "\t 33 | 00:25:04 ( 95) |  0.10 | 128 | 60% | 1000 |  -4.73% |  6.55% |   25 |  6.96% |   25\n",
      "\t 34 | 00:26:33 ( 89) |  0.01 | 128 | 95% |  500 |  -4.60% |  5.78% |  150 |  6.93% |  300\n",
      "\t 35 | 00:28:01 ( 88) |  0.10 | 128 | 60% |  500 |  -4.92% |  6.71% |   25 |  6.96% |   50\n",
      "\t 36 | 00:28:30 ( 29) |  0.10 |   4 | 60% | 1000 |  -5.81% |  7.43% |  100 |  7.92% |  100\n",
      "\t 37 | 00:29:03 ( 32) |  0.10 |   8 | 95% |  250 |  -5.70% |  7.12% |   75 |  7.27% |  100\n",
      "\t 38 | 00:29:36 ( 34) |  0.10 |   8 | 95% | 1000 |  -5.59% |  6.37% |   75 |  7.31% |   50\n",
      "\t 39 | 00:30:05 ( 29) |  0.30 |   4 | 95% |  250 |  -5.46% |  7.22% |   75 |  7.95% |   75\n",
      "\t 40 | 00:30:30 ( 25) |  0.10 |   4 | 30% |  250 |  -5.82% |  7.56% |  200 |  8.07% |  400\n",
      "\t 41 | 00:32:05 ( 94) |  0.10 | 128 | 95% | 1000 |  -4.80% |  5.36% |   25 |  6.50% |   25\n",
      "\t 42 | 00:32:38 ( 33) |  0.10 |   8 | 95% |  500 |  -5.53% |  6.37% |   75 |  7.17% |   50\n",
      "\t 43 | 00:33:28 ( 50) |  0.01 |  32 | 60% | 1000 |  -6.80% |  6.68% |  150 |  7.27% |  500\n",
      "\t 44 | 00:34:09 ( 41) |  0.30 |  32 | 30% | 1000 |  -4.82% |  6.79% |   10 |  6.93% |   10\n",
      "\t 45 | 00:34:43 ( 34) |  0.30 |  32 | 30% |  250 |  -4.74% |  6.37% |   10 |  6.84% |   10\n",
      "\t 46 | 00:35:52 ( 69) |  0.10 | 128 | 30% |  500 |  -4.96% |  6.24% |   10 |  6.89% |  100\n",
      "\t 47 | 00:36:55 ( 63) |  0.10 | 128 | 30% |  250 |  -4.93% |  6.51% |   50 |  7.02% |   50\n",
      "\t 48 | 00:37:26 ( 30) |  0.01 |   4 | 95% |  250 |  -12.34% |  7.46% |  500 |  7.32% |  500\n",
      "\t 49 | 00:37:57 ( 31) |  0.10 |   8 | 60% |  500 |  -4.95% |  7.02% |   75 |  7.25% |  250\n",
      "\t 50 | 00:38:44 ( 48) |  0.10 |  32 | 60% | 1000 |  -5.01% |  6.28% |   25 |  6.89% |  100\n",
      "\t 51 | 00:40:12 ( 87) |  0.30 | 128 | 60% |  500 |  -3.31% |  5.80% |   10 |  5.78% |   10\n",
      "\t 52 | 00:41:03 ( 52) |  0.01 |  32 | 60% |  500 |  -7.03% |  6.76% |  500 |  7.32% |   75\n",
      "\t 53 | 00:42:22 ( 79) |  0.01 | 128 | 60% | 1000 |  -5.97% |  6.57% |   50 |  7.37% |  350\n"
     ]
    }
   ],
   "source": [
    "# Takes around 6 hours to run the code:\n",
    "\n",
    "for lookahead, train_length, test_length in test_params:\n",
    "    # randomized grid search\n",
    "    cvp = np.random.choice(list(range(n_params)),\n",
    "                           size=int(n_params / 2),\n",
    "                           replace=False)\n",
    "    cv_params_ = [cv_params[i] for i in cvp]\n",
    "\n",
    "    # set up cross-validation\n",
    "    n_splits = int(2 * YEAR / test_length)\n",
    "    print(f'Lookahead: {lookahead:2.0f} | '\n",
    "          f'Train: {train_length:3.0f} | '\n",
    "          f'Test: {test_length:2.0f} | '\n",
    "          f'Params: {len(cv_params_):3.0f} | '\n",
    "          f'Train configs: {len(test_params)}')\n",
    "\n",
    "    # time-series cross-validation\n",
    "    cv = MultipleTimeSeriesCV(n_splits=n_splits,\n",
    "                              lookahead=lookahead,\n",
    "                              test_period_length=test_length,\n",
    "                              train_period_length=train_length)\n",
    "\n",
    "    label = label_dict[lookahead]\n",
    "    outcome_data = data.loc[:, features + [label]].dropna()\n",
    "    \n",
    "    # binary dataset\n",
    "    lgb_data = lgb.Dataset(data=outcome_data.drop(label, axis=1),\n",
    "                           label=outcome_data[label],\n",
    "                           categorical_feature=categoricals,\n",
    "                           free_raw_data=False)\n",
    "    T = 0\n",
    "    predictions, metrics, feature_importance, daily_ic = [], [], [], []\n",
    "    \n",
    "    # iterate over (shuffled) hyperparameter combinations\n",
    "    for p, param_vals in enumerate(cv_params_):\n",
    "        key = f'{lookahead}/{train_length}/{test_length}/' + '/'.join([str(p) for p in param_vals])\n",
    "        params = dict(zip(param_names, param_vals))\n",
    "        params.update(base_params)\n",
    "\n",
    "        start = time()\n",
    "        cv_preds, nrounds = [], []\n",
    "        ic_cv = defaultdict(list)\n",
    "        \n",
    "        # iterate over folds\n",
    "        for i, (train_idx, test_idx) in enumerate(cv.split(X=outcome_data)):\n",
    "            \n",
    "            # select train subset\n",
    "            lgb_train = lgb_data.subset(used_indices=train_idx.tolist(),\n",
    "                                       params=params).construct()\n",
    "            \n",
    "            # train model for num_boost_round\n",
    "            model = lgb.train(params=params,\n",
    "                              train_set=lgb_train,\n",
    "                              num_boost_round=num_boost_round,\n",
    "                              verbose_eval=False)\n",
    "            # log feature importance\n",
    "            if i == 0:\n",
    "                fi = get_fi(model).to_frame()\n",
    "            else:\n",
    "                fi[i] = get_fi(model)\n",
    "\n",
    "            # capture predictions\n",
    "            test_set = outcome_data.iloc[test_idx, :]\n",
    "            X_test = test_set.loc[:, model.feature_name()]\n",
    "            y_test = test_set.loc[:, label]\n",
    "            y_pred = {str(n): model.predict(X_test, num_iteration=n) for n in num_iterations}\n",
    "            \n",
    "            # record predictions for each fold\n",
    "            cv_preds.append(y_test.to_frame('y_test').assign(**y_pred).assign(i=i))\n",
    "        \n",
    "        # combine fold results\n",
    "        cv_preds = pd.concat(cv_preds).assign(**params)\n",
    "        predictions.append(cv_preds)\n",
    "        \n",
    "        # compute IC per day\n",
    "        by_day = cv_preds.groupby(level='date')\n",
    "        ic_by_day = pd.concat([by_day.apply(lambda x: spearmanr(x.y_test, x[str(n)])[0]).to_frame(n)\n",
    "                               for n in num_iterations], axis=1)\n",
    "        daily_ic_mean = ic_by_day.mean()\n",
    "        daily_ic_mean_n = daily_ic_mean.idxmax()\n",
    "        daily_ic_median = ic_by_day.median()\n",
    "        daily_ic_median_n = daily_ic_median.idxmax()\n",
    "        \n",
    "        # compute IC across all predictions\n",
    "        ic = [spearmanr(cv_preds.y_test, cv_preds[str(n)])[0] for n in num_iterations]\n",
    "        t = time() - start\n",
    "        T += t\n",
    "        \n",
    "        # collect metrics\n",
    "        metrics = pd.Series(list(param_vals) +\n",
    "                            [t, daily_ic_mean.max(), daily_ic_mean_n, daily_ic_median.max(), daily_ic_median_n] + ic,\n",
    "                            index=metric_cols)\n",
    "        msg = f'\\t{p:3.0f} | {format_time(T)} ({t:3.0f}) | {params[\"learning_rate\"]:5.2f} | '\n",
    "        msg += f'{params[\"num_leaves\"]:3.0f} | {params[\"feature_fraction\"]:3.0%} | {params[\"min_data_in_leaf\"]:4.0f} | '\n",
    "        msg += f' {max(ic):6.2%} | {ic_by_day.mean().max(): 6.2%} | {daily_ic_mean_n: 4.0f} | {ic_by_day.median().max(): 6.2%} | {daily_ic_median_n: 4.0f}'\n",
    "        print(msg)\n",
    "\n",
    "        # persist results for given CV run and hyperparameter combination, and store the results for the model\n",
    "        metrics.to_hdf(lgb_store, 'metrics/' + key)\n",
    "        ic_by_day.assign(**params).to_hdf(lgb_store, 'daily_ic/' + key)\n",
    "        fi.T.describe().T.assign(**params).to_hdf(lgb_store, 'fi/' + key)\n",
    "        cv_preds.to_hdf(lgb_store, 'predictions/' + key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.031px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
